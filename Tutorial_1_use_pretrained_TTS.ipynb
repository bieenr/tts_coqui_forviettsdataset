{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "45ea3ef5",
      "metadata": {
        "tags": [],
        "id": "45ea3ef5"
      },
      "source": [
        "# Easy Inferencing with üê∏ TTS ‚ö°\n",
        "\n",
        "#### You want to quicly synthesize speech using Coqui üê∏ TTS model?\n",
        "\n",
        "üí°: Grab a pre-trained model and use it to synthesize speech using any speaker voice, including yours! ‚ö°\n",
        "\n",
        "üê∏ TTS comes with a list of pretrained models and speaker voices. You can even start a local demo server that you can open it on your favorite web browser and üó£Ô∏è .\n",
        "\n",
        "In this notebook, we will:\n",
        "```\n",
        "1. List available pre-trained üê∏ TTS models\n",
        "2. Run a üê∏ TTS model\n",
        "3. Listen to the synthesized wave üì£\n",
        "4. Run multispeaker üê∏ TTS model\n",
        "```\n",
        "So, let's jump right in!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a1e5c2a5-46eb-42fd-b550-2a052546857e",
      "metadata": {
        "id": "a1e5c2a5-46eb-42fd-b550-2a052546857e"
      },
      "source": [
        "## Install üê∏ TTS ‚¨áÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fa2aec77",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa2aec77",
        "outputId": "3f27ed4f-c3b9-4777-9214-174b9ea2bec6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.2.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "  Attempting uninstall: pip\n",
            "    Found existing installation: pip 23.1.2\n",
            "    Uninstalling pip-23.1.2:\n",
            "      Successfully uninstalled pip-23.1.2\n",
            "Successfully installed pip-23.2.1\n",
            "Cloning into 'TTS'...\n",
            "remote: Enumerating objects: 30191, done.\u001b[K\n",
            "remote: Counting objects: 100% (1016/1016), done.\u001b[K\n",
            "remote: Compressing objects: 100% (447/447), done.\u001b[K\n",
            "remote: Total 30191 (delta 690), reused 799 (delta 552), pack-reused 29175\u001b[K\n",
            "Receiving objects: 100% (30191/30191), 159.30 MiB | 25.99 MiB/s, done.\n",
            "Resolving deltas: 100% (21842/21842), done.\n"
          ]
        }
      ],
      "source": [
        "! pip install -U pip\n",
        "! git clone https://github.com/coqui-ai/TTS.git"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8c07a273",
      "metadata": {
        "id": "8c07a273"
      },
      "source": [
        "## ‚úÖ List available pre-trained üê∏ TTS models\n",
        "\n",
        "Coqui üê∏TTS comes with a list of pretrained models for different model types (ex: TTS, vocoder), languages, datasets used for training and architectures.\n",
        "\n",
        "You can either use your own model or the release models under üê∏TTS.\n",
        "\n",
        "Use `tts --list_models` to find out the availble models.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "!cd /content/TTS/TTS/\n",
        "os.listdir()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLLwr5A4Rj_-",
        "outputId": "63467ba8-f2b4-42de-99b6-1f8954d86af9"
      },
      "id": "fLLwr5A4Rj_-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['.config', 'TTS', 'sample_data']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "608d203f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "608d203f",
        "outputId": "9d90c3d7-a241-4041-ecdd-637aa65316e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/TTS/TTS/bin/synthesize.py\", line 11, in <module>\n",
            "    from TTS.api import TTS\n",
            "ModuleNotFoundError: No module named 'TTS'\n"
          ]
        }
      ],
      "source": [
        "!python /content/TTS/TTS/bin/synthesize.py --list_models"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ed9dd7ab",
      "metadata": {
        "id": "ed9dd7ab"
      },
      "source": [
        "## ‚úÖ Run a üê∏ TTS model\n",
        "\n",
        "#### **First things first**: Using a release model and default vocoder:\n",
        "\n",
        "You can simply copy the full model name from the list above and use it\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc9e4608-16ec-4dcd-bd6b-bd10d62286f8",
      "metadata": {
        "id": "cc9e4608-16ec-4dcd-bd6b-bd10d62286f8"
      },
      "outputs": [],
      "source": [
        "!tts --text \"hello world\" \\\n",
        "--model_name \"tts_models/en/ljspeech/glow-tts\" \\\n",
        "--out_path output.wav\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ca2cb14-1aba-400e-a219-8ce44d9410be",
      "metadata": {
        "id": "0ca2cb14-1aba-400e-a219-8ce44d9410be"
      },
      "source": [
        "## üì£ Listen to the synthesized wave üì£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5fe63ef4-9284-4461-9dda-1ca7483a8f9b",
      "metadata": {
        "id": "5fe63ef4-9284-4461-9dda-1ca7483a8f9b"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"output.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5e67d178-1ebe-49c7-9a47-0593251bdb96",
      "metadata": {
        "id": "5e67d178-1ebe-49c7-9a47-0593251bdb96"
      },
      "source": [
        "### **Second things second**:\n",
        "\n",
        "üî∂ A TTS model can be either trained on a single speaker voice or multispeaker voices. This training choice is directly reflected on the inference ability and the available speaker voices that can be used to synthesize speech.\n",
        "\n",
        "üî∂ If you want to run a multispeaker model from the released models list, you can first check the speaker ids using `--list_speaker_idx` flag and use this speaker voice to synthesize speech."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "87b18839-f750-4a61-bbb0-c964acaecab2",
      "metadata": {
        "id": "87b18839-f750-4a61-bbb0-c964acaecab2"
      },
      "outputs": [],
      "source": [
        "# list the possible speaker IDs.\n",
        "!tts --model_name \"tts_models/en/vctk/vits\" \\\n",
        "--list_speaker_idxs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4365a9d-f922-4b14-88b0-d2b22a245b2e",
      "metadata": {
        "id": "c4365a9d-f922-4b14-88b0-d2b22a245b2e"
      },
      "source": [
        "## üí¨ Synthesize speech using speaker ID üí¨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52be0403-d13e-4d9b-99c2-c10b85154063",
      "metadata": {
        "id": "52be0403-d13e-4d9b-99c2-c10b85154063"
      },
      "outputs": [],
      "source": [
        "!tts --text \"Trying out specific speaker voice\"\\\n",
        "--out_path spkr-out.wav --model_name \"tts_models/en/vctk/vits\" \\\n",
        "--speaker_idx \"p341\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "894a560a-f9c8-48ce-aaa6-afdf516c01f6",
      "metadata": {
        "id": "894a560a-f9c8-48ce-aaa6-afdf516c01f6"
      },
      "source": [
        "## üì£ Listen to the synthesized speaker specific wave üì£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ed485b0a-dfd5-4a7e-a571-ebf74bdfc41d",
      "metadata": {
        "id": "ed485b0a-dfd5-4a7e-a571-ebf74bdfc41d"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"spkr-out.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "84636a38-097e-4dad-933b-0aeaee650e92",
      "metadata": {
        "id": "84636a38-097e-4dad-933b-0aeaee650e92"
      },
      "source": [
        "üî∂ If you want to use an external speaker to synthesize speech, you need to supply `--speaker_wav` flag along with an external speaker encoder path and config file, as follows:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbdb15fa-123a-4282-a127-87b50dc70365",
      "metadata": {
        "id": "cbdb15fa-123a-4282-a127-87b50dc70365"
      },
      "source": [
        "First we need to get the speaker encoder model, its config and a referece `speaker_wav`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e54f1b13-560c-4fed-bafd-e38ec9712359",
      "metadata": {
        "id": "e54f1b13-560c-4fed-bafd-e38ec9712359"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/coqui-ai/TTS/releases/download/speaker_encoder_model/config_se.json\n",
        "!wget https://github.com/coqui-ai/TTS/releases/download/speaker_encoder_model/model_se.pth.tar\n",
        "!wget https://github.com/coqui-ai/TTS/raw/speaker_encoder_model/tests/data/ljspeech/wavs/LJ001-0001.wav"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6dac1912-5054-4a68-8357-6d20fd99cb10",
      "metadata": {
        "id": "6dac1912-5054-4a68-8357-6d20fd99cb10"
      },
      "outputs": [],
      "source": [
        "!tts --model_name tts_models/multilingual/multi-dataset/your_tts \\\n",
        "--encoder_path model_se.pth.tar \\\n",
        "--encoder_config config_se.json \\\n",
        "--speaker_wav LJ001-0001.wav \\\n",
        "--text \"Are we not allowed to dim the lights so people can see that a bit better?\"\\\n",
        "--out_path spkr-out.wav \\\n",
        "--language_idx \"en\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92ddce58-8aca-4f69-84c3-645ae1b12e7d",
      "metadata": {
        "id": "92ddce58-8aca-4f69-84c3-645ae1b12e7d"
      },
      "source": [
        "## üì£ Listen to the synthesized speaker specific wave üì£"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cc889adc-9c71-4232-8e85-bfc8f76476f4",
      "metadata": {
        "id": "cc889adc-9c71-4232-8e85-bfc8f76476f4"
      },
      "outputs": [],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"spkr-out.wav\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "29101d01-0b01-4153-a216-5dae415a5dd6",
      "metadata": {
        "id": "29101d01-0b01-4153-a216-5dae415a5dd6"
      },
      "source": [
        "## üéâ Congratulations! üéâ You now know how to use a TTS model to synthesize speech!\n",
        "Follow up with the next tutorials to learn more adnavced material."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}