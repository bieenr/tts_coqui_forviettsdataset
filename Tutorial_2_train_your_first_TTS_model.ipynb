{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f79d99ef"
      },
      "source": [
        "# Train your first üê∏ TTS model üí´\n",
        "\n",
        "### üëã Hello and welcome to Coqui (üê∏) TTS\n",
        "\n",
        "The goal of this notebook is to show you a **typical workflow** for **training** and **testing** a TTS model with üê∏.\n",
        "\n",
        "Let's train a very small model on a very small amount of data so we can iterate quickly.\n",
        "\n",
        "In this notebook, we will:\n",
        "\n",
        "1. Download data and format it for üê∏ TTS.\n",
        "2. Configure the training and testing runs.\n",
        "3. Train a new model.\n",
        "4. Test the model and display its performance.\n",
        "\n",
        "So, let's jump right in!\n"
      ],
      "id": "f79d99ef"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa2aec78"
      },
      "outputs": [],
      "source": [
        "## Install Coqui TTS\n",
        "! pip install -U pip\n",
        "! pip install TTS\n"
      ],
      "id": "fa2aec78"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UaxfNPM45Fk5"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install espeak"
      ],
      "id": "UaxfNPM45Fk5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Su723m3L6jAP"
      },
      "outputs": [],
      "source": [
        "!tts -h"
      ],
      "id": "Su723m3L6jAP"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "be5fe49c"
      },
      "source": [
        "## ‚úÖ Data Preparation\n",
        "\n",
        "### **First things first**: we need some data.\n",
        "\n",
        "We're training a Text-to-Speech model, so we need some _text_ and we need some _speech_. Specificially, we want _transcribed speech_. The speech must be divided into audio clips and each clip needs transcription. More details about data requirements such as recording characteristics, background noise and vocabulary coverage can be found in the [üê∏TTS documentation](https://tts.readthedocs.io/en/latest/formatting_your_dataset.html).\n",
        "\n",
        "If you have a single audio file and you need to **split** it into clips. It is also important to use a lossless audio file format to prevent compression artifacts. We recommend using **wav** file format.\n",
        "\n",
        "The data format we will be adopting for this tutorial is taken from the widely-used  **LJSpeech** dataset, where **waves** are collected under a folder:\n",
        "\n",
        "<span style=\"color:purple;font-size:15px\">\n",
        "/wavs<br />\n",
        " &emsp;| - audio1.wav<br />\n",
        " &emsp;| - audio2.wav<br />\n",
        " &emsp;| - audio3.wav<br />\n",
        "  ...<br />\n",
        "</span>\n",
        "\n",
        "and a **metadata.csv** file will have the audio file name in parallel to the transcript, delimited by `|`:\n",
        "\n",
        "<span style=\"color:purple;font-size:15px\">\n",
        "# metadata.csv <br />\n",
        "audio1|This is my sentence. <br />\n",
        "audio2|This is maybe my sentence. <br />\n",
        "audio3|This is certainly my sentence. <br />\n",
        "audio4|Let this be your sentence. <br />\n",
        "...\n",
        "</span>\n",
        "\n",
        "In the end, we should have the following **folder structure**:\n",
        "\n",
        "<span style=\"color:purple;font-size:15px\">\n",
        "/MyTTSDataset <br />\n",
        "&emsp;| <br />\n",
        "&emsp;| -> metadata.csv<br />\n",
        "&emsp;| -> /wavs<br />\n",
        "&emsp;&emsp;| -> audio1.wav<br />\n",
        "&emsp;&emsp;| -> audio2.wav<br />\n",
        "&emsp;&emsp;| ...<br />\n",
        "</span>"
      ],
      "id": "be5fe49c"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69501a10-3b53-4e75-ae66-90221d6f2271"
      },
      "source": [
        "üê∏TTS already provides tooling for the _LJSpeech_. if you use the same format, you can start training your models right away. <br />\n",
        "\n",
        "After you collect and format your dataset, you need to check two things. Whether you need a **_formatter_** and a **_text_cleaner_**. <br /> The **_formatter_** loads the text file (created above) as a list and the **_text_cleaner_** performs a sequence of text normalization operations that converts the raw text into the spoken representation (e.g. converting numbers to text, acronyms, and symbols to the spoken format).\n",
        "\n",
        "If you use a different dataset format then the LJSpeech or the other public datasets that üê∏TTS supports, then you need to write your own **_formatter_** and  **_text_cleaner_**."
      ],
      "id": "69501a10-3b53-4e75-ae66-90221d6f2271"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e7f226c8-4e55-48fa-937b-8415d539b17c"
      },
      "source": [
        "## ‚è≥Ô∏è Loading your dataset\n",
        "Load one of the dataset supported by üê∏TTS.\n",
        "\n",
        "We will start by defining dataset config and setting LJSpeech as our target dataset and define its path.\n"
      ],
      "id": "e7f226c8-4e55-48fa-937b-8415d539b17c"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "b3cb0191-b8fc-4158-bd26-8423c2a8ba66"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# BaseDatasetConfig: defines name, formatter and path of the dataset.\n",
        "from TTS.tts.configs.shared_configs import BaseDatasetConfig\n",
        "\n",
        "output_path = \"tts_train_dir\"\n",
        "if not os.path.exists(output_path):\n",
        "    os.makedirs(output_path)\n"
      ],
      "id": "b3cb0191-b8fc-4158-bd26-8423c2a8ba66"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDdDtc5MvzR7",
        "outputId": "75eaa6a9-9427-48a0-9384-ac92faf277a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-07-20 15:28:37--  https://huggingface.co/datasets/ntt123/viet-tts-dataset/resolve/main/viet-tts.tar.gz\n",
            "Resolving huggingface.co (huggingface.co)... 108.138.94.27, 108.138.94.45, 108.138.94.52, ...\n",
            "Connecting to huggingface.co (huggingface.co)|108.138.94.27|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/b6/a0/b6a06f111e29ec13cce1bd8ac23c03399a91a255436d45e3107e1166e1aae0eb/e00f71ccfe907cd74a9cb1bcb60d058ec8a9aa8c4c101d019dbeeefc588c5d0b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27viet-tts.tar.gz%3B+filename%3D%22viet-tts.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1690126118&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MDEyNjExOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNi9hMC9iNmEwNmYxMTFlMjllYzEzY2NlMWJkOGFjMjNjMDMzOTlhOTFhMjU1NDM2ZDQ1ZTMxMDdlMTE2NmUxYWFlMGViL2UwMGY3MWNjZmU5MDdjZDc0YTljYjFiY2I2MGQwNThlYzhhOWFhOGM0YzEwMWQwMTlkYmVlZWZjNTg4YzVkMGI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=LkgsC7ZnxkqdT1gXaHSYvmSBPKUWvjKylnf0OtCXlVgiX4ak-Iw6pW1gJatz9gT2e-pE7vO5QwYS6vFs2QmgHUadrw2qIMx42dj%7EIwY0sOdmuynmGOluG3D3t0BYLNbFygQQG2EmigKsUdq20Us-pAtsVMG1RZpYkRPXEERRkZj7zbBRwSwnsESmwEPI9BqJJvh%7EhEiRcgLdzvnP9vLP-t8H5SKiuxinURQaCa2H5AfLrFDoQjwee6-XOehqxJkDbgPTo73PykcmyKn3hi-42nLQUBxghYWCWzfmNvt2KV1aT1HPO9rmJtjD05olDxoFI1Elqyq7w0nPuPhzxAro%7EQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-07-20 15:28:38--  https://cdn-lfs.huggingface.co/repos/b6/a0/b6a06f111e29ec13cce1bd8ac23c03399a91a255436d45e3107e1166e1aae0eb/e00f71ccfe907cd74a9cb1bcb60d058ec8a9aa8c4c101d019dbeeefc588c5d0b?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27viet-tts.tar.gz%3B+filename%3D%22viet-tts.tar.gz%22%3B&response-content-type=application%2Fgzip&Expires=1690126118&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5MDEyNjExOH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNi9hMC9iNmEwNmYxMTFlMjllYzEzY2NlMWJkOGFjMjNjMDMzOTlhOTFhMjU1NDM2ZDQ1ZTMxMDdlMTE2NmUxYWFlMGViL2UwMGY3MWNjZmU5MDdjZDc0YTljYjFiY2I2MGQwNThlYzhhOWFhOGM0YzEwMWQwMTlkYmVlZWZjNTg4YzVkMGI%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qJnJlc3BvbnNlLWNvbnRlbnQtdHlwZT0qIn1dfQ__&Signature=LkgsC7ZnxkqdT1gXaHSYvmSBPKUWvjKylnf0OtCXlVgiX4ak-Iw6pW1gJatz9gT2e-pE7vO5QwYS6vFs2QmgHUadrw2qIMx42dj%7EIwY0sOdmuynmGOluG3D3t0BYLNbFygQQG2EmigKsUdq20Us-pAtsVMG1RZpYkRPXEERRkZj7zbBRwSwnsESmwEPI9BqJJvh%7EhEiRcgLdzvnP9vLP-t8H5SKiuxinURQaCa2H5AfLrFDoQjwee6-XOehqxJkDbgPTo73PykcmyKn3hi-42nLQUBxghYWCWzfmNvt2KV1aT1HPO9rmJtjD05olDxoFI1Elqyq7w0nPuPhzxAro%7EQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.161.6.100, 18.161.6.81, 18.161.6.107, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.161.6.100|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 5696815492 (5.3G) [application/gzip]\n",
            "Saving to: ‚Äòviet-tts.tar.gz‚Äô\n",
            "\n",
            "viet-tts.tar.gz     100%[===================>]   5.30G   220MB/s    in 34s     \n",
            "\n",
            "2023-07-20 15:29:11 (161 MB/s) - ‚Äòviet-tts.tar.gz‚Äô saved [5696815492/5696815492]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://huggingface.co/datasets/ntt123/viet-tts-dataset/resolve/main/viet-tts.tar.gz -O viet-tts.tar.gz\n",
        "!mkdir -p dataset\n",
        "!tar -C dataset -xzf viet-tts.tar.gz"
      ],
      "id": "SDdDtc5MvzR7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae6b7019-3685-4b48-8917-c152e288d7e3"
      },
      "outputs": [],
      "source": [
        "# Download and extract LJSpeech dataset.\n",
        "\n",
        "!wget -O $output_path/LJSpeech-1.1.tar.bz2 https://data.keithito.com/data/speech/LJSpeech-1.1.tar.bz2\n",
        "!tar -xf $output_path/LJSpeech-1.1.tar.bz2 -C $output_path"
      ],
      "id": "ae6b7019-3685-4b48-8917-c152e288d7e3"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "BVJp_5Z-0rBi",
        "outputId": "b8c6f1a5-7486-4bb8-88d9-8f629e62156a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "UnicodeDecodeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-f80cdc02f131>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/encodings/ascii.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascii_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mStreamWriter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCodec\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStreamWriter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnicodeDecodeError\u001b[0m: 'ascii' codec can't decode byte 0xc4 in position 20: ordinal not in range(128)"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "\n",
        "file_path = '/content/dataset/meta_data.tsv'  # Replace with the actual path to your text file\n",
        "\n",
        "# Method 1: Using the 'open' function\n",
        "count = 0\n",
        "data = []\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        count += 1\n",
        "        # print(line.strip().split(\"\\t\"))\n",
        "        name_file, text_file = line.strip().split(\"\\t\")\n",
        "        format_name = name_file.split(\"/\")[1].split(\".\")[0]\n",
        "        data.append([format_name,text_file,text_file])\n",
        "        if count == 17000:\n",
        "          break\n",
        "file.close()\n",
        "print(len(data))\n",
        "output_file = '/content/dataset/metadata.csv'\n",
        "\n",
        "# Write the data to the CSV file with \"|\" as the delimiter\n",
        "with open(output_file, 'w', newline='') as csvfile:\n",
        "    csv_writer = csv.writer(csvfile, delimiter='|')  # Set the delimiter to \"|\"\n",
        "    csv_writer.writerows(data)\n",
        "\n",
        "print(\"Data has been written to the CSV file.\")\n",
        "csvfile.close()\n"
      ],
      "id": "BVJp_5Z-0rBi"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fBn8iOhdxqRn"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output\n",
        "file_path =  '/content/tts_train_dir/LJSpeech-1.1/metadata.csv'  # Replace with the actual path to your text file\n",
        "\n",
        "# Method 1: Using the 'open' function\n",
        "count = 0\n",
        "with open(file_path, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "    for line in lines:\n",
        "        count += 1\n",
        "        # print(line.strip())\n",
        "        raw = line.strip().split(\"|\")\n",
        "        for i in raw :\n",
        "          print(i)\n",
        "        if count == 50 :\n",
        "          break\n",
        "\n",
        "# clear_output()"
      ],
      "id": "fBn8iOhdxqRn"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "76cd3ab5-6387-45f1-b488-24734cc1beb5"
      },
      "outputs": [],
      "source": [
        "# dataset_config = BaseDatasetConfig(\n",
        "#     formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=os.path.join(output_path, \"LJSpeech-1.1/\")\n",
        "# )\n",
        "\n",
        "dataset_config = BaseDatasetConfig(\n",
        "    formatter=\"ljspeech\", meta_file_train=\"metadata.csv\", path=\"/content/dataset\"\n",
        ")"
      ],
      "id": "76cd3ab5-6387-45f1-b488-24734cc1beb5"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ae82fd75"
      },
      "source": [
        "## ‚úÖ Train a new model\n",
        "\n",
        "Let's kick off a training run üöÄüöÄüöÄ.\n",
        "\n",
        "Deciding on the model architecture you'd want to use is based on your needs and available resources. Each model architecture has it's pros and cons that define the run-time efficiency and the voice quality.\n",
        "We have many recipes under `TTS/recipes/` that provide a good starting point. For this tutorial, we will be using `GlowTTS`."
      ],
      "id": "ae82fd75"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5876e46-2aee-4bcf-b6b3-9e3c535c553f"
      },
      "source": [
        "We will begin by initializing the model training configuration."
      ],
      "id": "f5876e46-2aee-4bcf-b6b3-9e3c535c553f"
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5483ca28-39d6-49f8-a18e-4fb53c50ad84"
      },
      "outputs": [],
      "source": [
        "# GlowTTSConfig: all model related values for training, validating and testing.\n",
        "from TTS.tts.configs.glow_tts_config import GlowTTSConfig\n",
        "config = GlowTTSConfig(\n",
        "    batch_size=32,\n",
        "    eval_batch_size=16,\n",
        "    num_loader_workers=4,\n",
        "    num_eval_loader_workers=4,\n",
        "    run_eval=True,\n",
        "    test_delay_epochs=-1,\n",
        "    epochs=3,\n",
        "    text_cleaner=\"phoneme_cleaners\",\n",
        "    use_phonemes=True,\n",
        "    phoneme_language=\"en-us\",\n",
        "    phoneme_cache_path=os.path.join(output_path, \"phoneme_cache\"),\n",
        "    print_step=25,\n",
        "    print_eval=False,\n",
        "    mixed_precision=True,\n",
        "    output_path=output_path,\n",
        "    datasets=[dataset_config],\n",
        "    save_step=1000,\n",
        ")"
      ],
      "id": "5483ca28-39d6-49f8-a18e-4fb53c50ad84"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b93ed377-80b7-447b-bd92-106bffa777ee"
      },
      "source": [
        "Next we will initialize the audio processor which is used for feature extraction and audio I/O."
      ],
      "id": "b93ed377-80b7-447b-bd92-106bffa777ee"
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "b1b12f61-f851-4565-84dd-7640947e04ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2387035d-8e23-44f5-d69c-559c30d4df91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " > Setting up Audio Processor...\n",
            " | > sample_rate:22050\n",
            " | > resample:False\n",
            " | > num_mels:80\n",
            " | > log_func:np.log10\n",
            " | > min_level_db:-100\n",
            " | > frame_shift_ms:None\n",
            " | > frame_length_ms:None\n",
            " | > ref_level_db:20\n",
            " | > fft_size:1024\n",
            " | > power:1.5\n",
            " | > preemphasis:0.0\n",
            " | > griffin_lim_iters:60\n",
            " | > signal_norm:True\n",
            " | > symmetric_norm:True\n",
            " | > mel_fmin:0\n",
            " | > mel_fmax:None\n",
            " | > pitch_fmin:1.0\n",
            " | > pitch_fmax:640.0\n",
            " | > spec_gain:20.0\n",
            " | > stft_pad_mode:reflect\n",
            " | > max_norm:4.0\n",
            " | > clip_norm:True\n",
            " | > do_trim_silence:True\n",
            " | > trim_db:45\n",
            " | > do_sound_norm:False\n",
            " | > do_amp_to_db_linear:True\n",
            " | > do_amp_to_db_mel:True\n",
            " | > do_rms_norm:False\n",
            " | > db_level:None\n",
            " | > stats_path:None\n",
            " | > base:10\n",
            " | > hop_length:256\n",
            " | > win_length:1024\n"
          ]
        }
      ],
      "source": [
        "from TTS.utils.audio import AudioProcessor\n",
        "ap = AudioProcessor.init_from_config(config)\n",
        "# Modify sample rate if for a custom audio dataset:\n",
        "# ap.sample_rate = 22050\n"
      ],
      "id": "b1b12f61-f851-4565-84dd-7640947e04ab"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1d461683-b05e-403f-815f-8007bda08c38"
      },
      "source": [
        "Next we will initialize the tokenizer which is used to convert text to sequences of token IDs.  If characters are not defined in the config, default characters are passed to the config."
      ],
      "id": "1d461683-b05e-403f-815f-8007bda08c38"
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "014879b7-f18d-44c0-b24a-e10f8002113a"
      },
      "outputs": [],
      "source": [
        "from TTS.tts.utils.text.tokenizer import TTSTokenizer\n",
        "tokenizer, config = TTSTokenizer.init_from_config(config)"
      ],
      "id": "014879b7-f18d-44c0-b24a-e10f8002113a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "df3016e1-9e99-4c4f-94e3-fa89231fd978"
      },
      "source": [
        "Next we will load data samples. Each sample is a list of ```[text, audio_file_path, speaker_name]```. You can define your custom sample loader returning the list of samples."
      ],
      "id": "df3016e1-9e99-4c4f-94e3-fa89231fd978"
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cadd6ada-c8eb-4f79-b8fe-6d72850af5a7",
        "outputId": "7da51b8f-8bbf-44cd-8adc-3c18a2fb10dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " | > Found 21000 files in /content/dataset\n"
          ]
        }
      ],
      "source": [
        "from TTS.tts.datasets import load_tts_samples\n",
        "train_samples, eval_samples = load_tts_samples(\n",
        "    dataset_config,\n",
        "    eval_split=True,\n",
        "    eval_split_max_size=config.eval_split_max_size,\n",
        "    eval_split_size=config.eval_split_size,\n",
        ")"
      ],
      "id": "cadd6ada-c8eb-4f79-b8fe-6d72850af5a7"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "db8b451e-1fe1-4aa3-b69e-ab22b925bd19"
      },
      "source": [
        "Now we're ready to initialize the model.\n",
        "\n",
        "Models take a config object and a speaker manager as input. Config defines the details of the model like the number of layers, the size of the embedding, etc. Speaker manager is used by multi-speaker models."
      ],
      "id": "db8b451e-1fe1-4aa3-b69e-ab22b925bd19"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "ac2ffe3e-ad0c-443e-800c-9b076ee811b4"
      },
      "outputs": [],
      "source": [
        "from TTS.tts.models.glow_tts import GlowTTS\n",
        "model = GlowTTS(config, ap, tokenizer, speaker_manager=None)"
      ],
      "id": "ac2ffe3e-ad0c-443e-800c-9b076ee811b4"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e2832c56-889d-49a6-95b6-eb231892ecc6"
      },
      "source": [
        "Trainer provides a generic API to train all the üê∏TTS models with all its perks like mixed-precision training, distributed training, etc."
      ],
      "id": "e2832c56-889d-49a6-95b6-eb231892ecc6"
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0f609945-4fe0-4d0d-b95e-11d7bfb63ebe",
        "outputId": "d73df721-54ec-4100-e2f0-90964440dc13"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " > Training Environment:\n",
            " | > Backend: Torch\n",
            " | > Mixed precision: True\n",
            " | > Precision: fp16\n",
            " | > Current device: 0\n",
            " | > Num. of GPUs: 1\n",
            " | > Num. of CPUs: 2\n",
            " | > Num. of Torch Threads: 1\n",
            " | > Torch seed: 54321\n",
            " | > Torch CUDNN: True\n",
            " | > Torch CUDNN deterministic: False\n",
            " | > Torch CUDNN benchmark: False\n",
            " | > Torch TF32 MatMul: False\n",
            " > Start Tensorboard: tensorboard --logdir=tts_train_dir/run-July-20-2023_03+33PM-0000000\n",
            "\n",
            " > Model has 28610257 parameters\n"
          ]
        }
      ],
      "source": [
        "from trainer import Trainer, TrainerArgs\n",
        "trainer = Trainer(\n",
        "    TrainerArgs(), config, output_path, model=model, train_samples=train_samples, eval_samples=eval_samples\n",
        ")"
      ],
      "id": "0f609945-4fe0-4d0d-b95e-11d7bfb63ebe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5b320831-dd83-429b-bb6a-473f9d49d321"
      },
      "source": [
        "### AND... 3,2,1... START TRAINING üöÄüöÄüöÄ"
      ],
      "id": "5b320831-dd83-429b-bb6a-473f9d49d321"
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "d4c07f99-3d1d-4bea-801e-9f33bbff0e9f",
        "outputId": "def1a18a-7981-476e-bad2-bfc9d2e57c4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[4m\u001b[1m > EPOCH: 0/3\u001b[0m\n",
            " --> tts_train_dir/run-July-20-2023_03+33PM-0000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] Pre-computing phonemes...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|‚ñà‚ñà        | 4289/20790 [03:07<10:40, 25.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Àà…ëÀê≈ã kÀào ä bÀàiÀê Ààa…™ lÀå…õ…æ…öwÀà ånÀàiÀêbÀàiÀêÀà…õf tÀàiÀê kÀà…ëÀê≈ã? nÀào ä vÀàiÀê lÀå…õ…æ…öwÀà ånÀàiÀêdÀàiÀêbÀàiÀê Ààa…™ k ÉÀàuÀê√¶n Àå…ëÀê…πlÀå…õ…æ…öwÀå ånÀàiÀêÀåiÀêsÀà…õv…ôn Àà…õnhÀàa ä vÀà√¶o ä Àå…õmlÀå…õ…æ…öwÀå ånÀàiÀêdÀåiÀênÀåa…™ntÀàiÀê Àào ä înÃ© Œ∏Àà å…õÀê bÀàiÀê jÀàuÀê lÀå…õ…æ…öwÀà ånÀàiÀêdÀàiÀêŒ∏…πÀàiÀê Àà…õn d íÀàiÀê! sÀåiÀêÀåe…™t ÉlÀå…õ…æ…öwÀà ånÀåiÀêbÀåiÀêÀå…õftÀàiÀê tÀåiÀêÀåe…™t ÉlÀå…õ…æ…öwÀà ånÀåiÀêÀåe…™dÀåiÀêtÀàiÀê sÀåiÀêÀåe…™t ÉlÀå…õ…æ…öwÀà ånÀåiÀêÀåiÀênÀàa…™n kÀà…ëÀê≈ã Àå…õnd íÀåiÀêlÀå…õ…æ…öwÀà ånÀåiÀêdÀåiÀêdÀàiÀê Àå…ëÀê…πlÀå…õ…æ…öwÀå ånÀàiÀêbÀåiÀêwÀå ånÀå…õnd íÀàiÀê...\n",
            " [!] Character 'Ã©' not found in the vocabulary. Discarding it.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 20790/20790 [15:16<00:00, 22.70it/s]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "\n",
            "\u001b[1m > TRAINING (2023-07-20 15:49:29) \u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "> DataLoader initialization\n",
            "| > Tokenizer:\n",
            "\t| > add_blank: False\n",
            "\t| > use_eos_bos: False\n",
            "\t| > use_phonemes: True\n",
            "\t| > phonemizer:\n",
            "\t\t| > phoneme language: en-us\n",
            "\t\t| > phoneme backend: espeak\n",
            "\t| > 1 not found characters:\n",
            "\t| > Ã©\n",
            "| > Number of instances : 20790\n",
            " | > Preprocessing samples\n",
            " | > Max text length: 281\n",
            " | > Min text length: 4\n",
            " | > Avg text length: 96.09057239057239\n",
            " | \n",
            " | > Max audio length: 677917.0\n",
            " | > Min audio length: 20509.0\n",
            " | > Avg audio length: 247597.0815776816\n",
            " | > Num. instances discarded samples: 0\n",
            " | > Batch group size: 0.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:49:43 -- STEP: 0/650 -- GLOBAL_STEP: 0\u001b[0m\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 11.7519  (11.751869440078735)\n",
            "     | > loader_time: 3.1018  (3.101792097091675)\n",
            "\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            " [!] `train_step()` retuned `None` outputs. Skipping training step.\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:49:58 -- STEP: 25/650 -- GLOBAL_STEP: 25\u001b[0m\n",
            "     | > loss: 1.112144947052002  (1.1652427275975545)\n",
            "     | > log_mle: 0.6656221151351929  (0.649630343914032)\n",
            "     | > loss_dur: 0.4465228319168091  (0.5156124035517374)\n",
            "     | > amp_scaler: 32768.0  (37137.066666666666)\n",
            "     | > grad_norm: tensor(2.8382, device='cuda:0')  (tensor(2.8009, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.9049  (0.5857473182678222)\n",
            "     | > loader_time: 0.0043  (6.459844226837158)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:50:13 -- STEP: 50/650 -- GLOBAL_STEP: 50\u001b[0m\n",
            "     | > loss: 1.1233141422271729  (1.1362579256296157)\n",
            "     | > log_mle: 0.6541018486022949  (0.6516845867037774)\n",
            "     | > loss_dur: 0.46921229362487793  (0.4845733493566513)\n",
            "     | > amp_scaler: 32768.0  (34406.39999999999)\n",
            "     | > grad_norm: tensor(2.9468, device='cuda:0')  (tensor(2.9236, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.4893  (0.5755462598800658)\n",
            "     | > loader_time: 0.0119  (3.232243437767029)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:50:30 -- STEP: 75/650 -- GLOBAL_STEP: 75\u001b[0m\n",
            "     | > loss: 1.1093639135360718  (1.1224295194332414)\n",
            "     | > log_mle: 0.6550793051719666  (0.6537321255757259)\n",
            "     | > loss_dur: 0.4542846083641052  (0.4686973979839912)\n",
            "     | > amp_scaler: 32768.0  (33776.24615384614)\n",
            "     | > grad_norm: tensor(3.2330, device='cuda:0')  (tensor(2.9683, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.3534  (0.6121913878122964)\n",
            "     | > loader_time: 0.0039  (2.1564500554402675)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:50:49 -- STEP: 100/650 -- GLOBAL_STEP: 100\u001b[0m\n",
            "     | > loss: 1.0625507831573486  (1.1092874818378022)\n",
            "     | > log_mle: 0.6523020267486572  (0.6551350043879616)\n",
            "     | > loss_dur: 0.410248726606369  (0.45415247877438863)\n",
            "     | > amp_scaler: 32768.0  (33496.177777777775)\n",
            "     | > grad_norm: tensor(2.7457, device='cuda:0')  (tensor(2.9613, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 1.1987  (0.6428449583053586)\n",
            "     | > loader_time: 0.0117  (1.6193038010597234)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:51:11 -- STEP: 125/650 -- GLOBAL_STEP: 125\u001b[0m\n",
            "     | > loss: 1.0458539724349976  (1.0969083609788315)\n",
            "     | > log_mle: 0.6618781089782715  (0.656277236731156)\n",
            "     | > loss_dur: 0.38397589325904846  (0.44063112424767537)\n",
            "     | > amp_scaler: 32768.0  (33337.87826086956)\n",
            "     | > grad_norm: tensor(2.7620, device='cuda:0')  (tensor(2.9537, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.6077  (0.6939877109527586)\n",
            "     | > loader_time: 0.0122  (1.297141307830811)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:51:31 -- STEP: 150/650 -- GLOBAL_STEP: 150\u001b[0m\n",
            "     | > loss: 1.0087131261825562  (1.0887687900236678)\n",
            "     | > log_mle: 0.6623052358627319  (0.6566974124738149)\n",
            "     | > loss_dur: 0.3464079201221466  (0.4320713773369789)\n",
            "     | > amp_scaler: 32768.0  (33236.11428571429)\n",
            "     | > grad_norm: tensor(2.7624, device='cuda:0')  (tensor(2.9755, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.4546  (0.7075976403554278)\n",
            "     | > loader_time: 0.0038  (1.082300168673198)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:51:53 -- STEP: 175/650 -- GLOBAL_STEP: 175\u001b[0m\n",
            "     | > loss: 1.059654712677002  (1.0846942334464105)\n",
            "     | > log_mle: 0.6516035795211792  (0.6568613247437909)\n",
            "     | > loss_dur: 0.40805119276046753  (0.42783290816075875)\n",
            "     | > amp_scaler: 32768.0  (33165.18787878787)\n",
            "     | > grad_norm: tensor(3.3455, device='cuda:0')  (tensor(3.0086, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.7508  (0.7287822805132185)\n",
            "     | > loader_time: 0.012  (0.9293158749171666)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:52:16 -- STEP: 200/650 -- GLOBAL_STEP: 200\u001b[0m\n",
            "     | > loss: 1.053873062133789  (1.0782547878591644)\n",
            "     | > log_mle: 0.6618931889533997  (0.6571973383426662)\n",
            "     | > loss_dur: 0.3919799327850342  (0.42105745218302076)\n",
            "     | > amp_scaler: 32768.0  (33112.92631578945)\n",
            "     | > grad_norm: tensor(3.1062, device='cuda:0')  (tensor(3.0096, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.813  (0.7484134769439698)\n",
            "     | > loader_time: 0.0107  (0.814888482093811)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:52:40 -- STEP: 225/650 -- GLOBAL_STEP: 225\u001b[0m\n",
            "     | > loss: 1.0015673637390137  (1.0733609859333484)\n",
            "     | > log_mle: 0.6600540280342102  (0.6573689735212989)\n",
            "     | > loss_dur: 0.34151333570480347  (0.41599201573881994)\n",
            "     | > amp_scaler: 32768.0  (33072.81860465115)\n",
            "     | > grad_norm: tensor(2.8654, device='cuda:0')  (tensor(3.0153, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.8317  (0.770641934076945)\n",
            "     | > loader_time: 0.0137  (0.7256608528561063)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:53:07 -- STEP: 250/650 -- GLOBAL_STEP: 250\u001b[0m\n",
            "     | > loss: 1.061174988746643  (1.0680981477101648)\n",
            "     | > log_mle: 0.6566119194030762  (0.6574611728390055)\n",
            "     | > loss_dur: 0.4045630395412445  (0.41063697785139086)\n",
            "     | > amp_scaler: 32768.0  (33041.066666666644)\n",
            "     | > grad_norm: tensor(3.1943, device='cuda:0')  (tensor(3.0136, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 1.6109  (0.8027979927062988)\n",
            "     | > loader_time: 0.027  (0.6545014095306396)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:53:37 -- STEP: 275/650 -- GLOBAL_STEP: 275\u001b[0m\n",
            "     | > loss: 1.016508936882019  (1.0620139355929397)\n",
            "     | > log_mle: 0.6602758169174194  (0.6576024878699822)\n",
            "     | > loss_dur: 0.3562330901622772  (0.40441145019711183)\n",
            "     | > amp_scaler: 32768.0  (33015.30566037733)\n",
            "     | > grad_norm: tensor(3.1035, device='cuda:0')  (tensor(3.0030, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 0.8939  (0.8346956001628529)\n",
            "     | > loader_time: 0.0038  (0.5962661760503596)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:54:08 -- STEP: 300/650 -- GLOBAL_STEP: 300\u001b[0m\n",
            "     | > loss: 1.0091667175292969  (1.057060178394976)\n",
            "     | > log_mle: 0.6582773923873901  (0.6576855957508083)\n",
            "     | > loss_dur: 0.3508893847465515  (0.3993745853160989)\n",
            "     | > amp_scaler: 32768.0  (32993.98620689652)\n",
            "     | > grad_norm: tensor(3.0336, device='cuda:0')  (tensor(2.9977, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 1.6428  (0.8682587854067485)\n",
            "     | > loader_time: 0.0099  (0.5477312159538271)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:54:43 -- STEP: 325/650 -- GLOBAL_STEP: 325\u001b[0m\n",
            "     | > loss: 0.9923800826072693  (1.0513192884505744)\n",
            "     | > log_mle: 0.6569235920906067  (0.6578024820675923)\n",
            "     | > loss_dur: 0.3354564905166626  (0.39351680874824524)\n",
            "     | > amp_scaler: 32768.0  (32976.05079365077)\n",
            "     | > grad_norm: tensor(2.9010, device='cuda:0')  (tensor(2.9820, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 1.2164  (0.9083377706087553)\n",
            "     | > loader_time: 0.0089  (0.5065801965273347)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:55:22 -- STEP: 350/650 -- GLOBAL_STEP: 350\u001b[0m\n",
            "     | > loss: 1.0455224514007568  (1.0468405067920694)\n",
            "     | > log_mle: 0.6597621440887451  (0.6579722169567553)\n",
            "     | > loss_dur: 0.3857603669166565  (0.38886829237727577)\n",
            "     | > amp_scaler: 32768.0  (32960.75294117646)\n",
            "     | > grad_norm: tensor(3.3644, device='cuda:0')  (tensor(2.9792, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 1.294  (0.9538958460944039)\n",
            "     | > loader_time: 0.0232  (0.4712640387671336)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:56:09 -- STEP: 375/650 -- GLOBAL_STEP: 375\u001b[0m\n",
            "     | > loss: 0.9866014719009399  (1.0420765272558559)\n",
            "     | > log_mle: 0.6524354815483093  (0.6580367896654832)\n",
            "     | > loss_dur: 0.3341659903526306  (0.3840397394683265)\n",
            "     | > amp_scaler: 32768.0  (32947.5506849315)\n",
            "     | > grad_norm: tensor(2.9758, device='cuda:0')  (tensor(2.9671, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 1.4318  (1.0131633516947427)\n",
            "     | > loader_time: 0.0051  (0.4405488866170249)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:56:57 -- STEP: 400/650 -- GLOBAL_STEP: 400\u001b[0m\n",
            "     | > loss: 0.9142696857452393  (1.0371110700643988)\n",
            "     | > log_mle: 0.6626741886138916  (0.6580758484510276)\n",
            "     | > loss_dur: 0.25159546732902527  (0.37903522260678135)\n",
            "     | > amp_scaler: 32768.0  (32936.04102564104)\n",
            "     | > grad_norm: tensor(1.9757, device='cuda:0')  (tensor(2.9486, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 3.013  (1.0698226088285445)\n",
            "     | > loader_time: 0.018  (0.4136920362710954)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:57:49 -- STEP: 425/650 -- GLOBAL_STEP: 425\u001b[0m\n",
            "     | > loss: 0.9147917032241821  (1.0330730337694476)\n",
            "     | > log_mle: 0.6595479249954224  (0.6580836321934161)\n",
            "     | > loss_dur: 0.25524377822875977  (0.37498940240187834)\n",
            "     | > amp_scaler: 32768.0  (32925.91807228917)\n",
            "     | > grad_norm: tensor(2.2203, device='cuda:0')  (tensor(2.9378, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 1.6572  (1.12915509111741)\n",
            "     | > loader_time: 0.0059  (0.3899041428285488)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:58:48 -- STEP: 450/650 -- GLOBAL_STEP: 450\u001b[0m\n",
            "     | > loss: 1.00574791431427  (1.0283656133846808)\n",
            "     | > log_mle: 0.6594246625900269  (0.6579959277402272)\n",
            "     | > loss_dur: 0.3463232219219208  (0.3703696866604416)\n",
            "     | > amp_scaler: 32768.0  (32916.945454545465)\n",
            "     | > grad_norm: tensor(3.2624, device='cuda:0')  (tensor(2.9177, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 1.9512  (1.1968832429250087)\n",
            "     | > loader_time: 0.0057  (0.3686563677257963)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 15:59:51 -- STEP: 475/650 -- GLOBAL_STEP: 475\u001b[0m\n",
            "     | > loss: 0.9254375696182251  (1.0243997662298152)\n",
            "     | > log_mle: 0.6558398008346558  (0.6578978607731482)\n",
            "     | > loss_dur: 0.26959776878356934  (0.3665019063859859)\n",
            "     | > amp_scaler: 32768.0  (32908.93763440859)\n",
            "     | > grad_norm: tensor(2.4165, device='cuda:0')  (tensor(2.9036, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 2.1622  (1.2653646499232247)\n",
            "     | > loader_time: 0.0063  (0.34967980234246515)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 16:01:01 -- STEP: 500/650 -- GLOBAL_STEP: 500\u001b[0m\n",
            "     | > loss: 0.9384745955467224  (1.0204338522589949)\n",
            "     | > log_mle: 0.6523088216781616  (0.657732360095394)\n",
            "     | > loss_dur: 0.2861657738685608  (0.36270149307591587)\n",
            "     | > amp_scaler: 32768.0  (32901.74693877549)\n",
            "     | > grad_norm: tensor(2.3752, device='cuda:0')  (tensor(2.8882, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 3.607  (1.3415106463432316)\n",
            "     | > loader_time: 0.0172  (0.3326479334831239)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 16:02:20 -- STEP: 525/650 -- GLOBAL_STEP: 525\u001b[0m\n",
            "     | > loss: 1.012681484222412  (1.0167789146738153)\n",
            "     | > log_mle: 0.6574586629867554  (0.6575969981915744)\n",
            "     | > loss_dur: 0.35522282123565674  (0.3591819175528092)\n",
            "     | > amp_scaler: 32768.0  (32895.254368932015)\n",
            "     | > grad_norm: tensor(3.4793, device='cuda:0')  (tensor(2.8724, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 3.4407  (1.4278919183640257)\n",
            "     | > loader_time: 0.0068  (0.317248398917062)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 16:03:42 -- STEP: 550/650 -- GLOBAL_STEP: 550\u001b[0m\n",
            "     | > loss: 0.9176023006439209  (1.0136007686456052)\n",
            "     | > log_mle: 0.657792329788208  (0.6574878677173899)\n",
            "     | > loss_dur: 0.2598099708557129  (0.3561129021147888)\n",
            "     | > amp_scaler: 32768.0  (32889.362962962936)\n",
            "     | > grad_norm: tensor(2.1712, device='cuda:0')  (tensor(2.8624, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 4.0349  (1.5104967945272274)\n",
            "     | > loader_time: 0.0067  (0.3032313867048785)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 16:05:11 -- STEP: 575/650 -- GLOBAL_STEP: 575\u001b[0m\n",
            "     | > loss: 0.9289255738258362  (1.0103754434965362)\n",
            "     | > log_mle: 0.6577663421630859  (0.6573535010877966)\n",
            "     | > loss_dur: 0.27115923166275024  (0.35302194349006233)\n",
            "     | > amp_scaler: 32768.0  (32883.99292035394)\n",
            "     | > grad_norm: tensor(2.5470, device='cuda:0')  (tensor(2.8501, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 2.7805  (1.5996260228364363)\n",
            "     | > loader_time: 0.0073  (0.2904773554594621)\n",
            "\n",
            "\n",
            "\u001b[1m   --> TIME: 2023-07-20 16:06:44 -- STEP: 600/650 -- GLOBAL_STEP: 600\u001b[0m\n",
            "     | > loss: 0.900956928730011  (1.006920329898091)\n",
            "     | > log_mle: 0.6505159735679626  (0.6572135807093931)\n",
            "     | > loss_dur: 0.25044095516204834  (0.3497067505020209)\n",
            "     | > amp_scaler: 32768.0  (32879.07796610165)\n",
            "     | > grad_norm: tensor(2.1248, device='cuda:0')  (tensor(2.8338, device='cuda:0'))\n",
            "     | > current_lr: 2.5e-07 \n",
            "     | > step_time: 4.9956  (1.6881924359003702)\n",
            "     | > loader_time: 0.0168  (0.27871982415517194)\n",
            "\n",
            " ! Run is removed from tts_train_dir/run-July-20-2023_03+33PM-0000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1809, in fit\n",
            "    self._fit()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1761, in _fit\n",
            "    self.train_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1490, in train_epoch\n",
            "    outputs, _ = self.train_step(batch, batch_num_steps, cur_step, loader_start_time)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1348, in train_step\n",
            "    outputs, loss_dict_new, step_time = self.optimize(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1212, in optimize\n",
            "    outputs, loss_dict = self._compute_loss(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1143, in _compute_loss\n",
            "    outputs, loss_dict = self._model_train_step(batch, model, criterion)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1102, in _model_train_step\n",
            "    return model.train_step(*input_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/TTS/tts/models/glow_tts.py\", line 407, in train_step\n",
            "    outputs = self.forward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/TTS/tts/models/glow_tts.py\", line 247, in forward\n",
            "    logp = logp1 + logp2 + logp3 + logp4  # [b, t, t']\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 14.75 GiB total capacity; 12.72 GiB already allocated; 44.81 MiB free; 13.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1809, in fit\n",
            "    self._fit()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1761, in _fit\n",
            "    self.train_epoch()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1490, in train_epoch\n",
            "    outputs, _ = self.train_step(batch, batch_num_steps, cur_step, loader_start_time)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1348, in train_step\n",
            "    outputs, loss_dict_new, step_time = self.optimize(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1212, in optimize\n",
            "    outputs, loss_dict = self._compute_loss(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1143, in _compute_loss\n",
            "    outputs, loss_dict = self._model_train_step(batch, model, criterion)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1102, in _model_train_step\n",
            "    return model.train_step(*input_args)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/TTS/tts/models/glow_tts.py\", line 407, in train_step\n",
            "    outputs = self.forward(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/TTS/tts/models/glow_tts.py\", line 247, in forward\n",
            "    logp = logp1 + logp2 + logp3 + logp4  # [b, t, t']\n",
            "torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 14.75 GiB total capacity; 12.72 GiB already allocated; 44.81 MiB free; 13.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-15-b6cd7ba69c0e>\", line 1, in <cell line: 1>\n",
            "    trainer.fit()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\", line 1838, in fit\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1667, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1808\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1809\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1810\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1760\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_train_epoch\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_with_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1761\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1762\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_eval\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1489\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mcur_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m             \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_num_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcur_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloader_start_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1491\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, batch, batch_n_steps, step, loader_start_time)\u001b[0m\n\u001b[1;32m   1347\u001b[0m                 \u001b[0;31m# auto training with a single optimizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m                 outputs, loss_dict_new, step_time = self.optimize(\n\u001b[0m\u001b[1;32m   1349\u001b[0m                     \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36moptimize\u001b[0;34m(self, batch, model, optimizer, scaler, criterion, scheduler, config, optimizer_idx, step_optimizer, num_optimizers)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0;31m# forward pass and loss computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1212\u001b[0;31m         outputs, loss_dict = self._compute_loss(\n\u001b[0m\u001b[1;32m   1213\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_idx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_idx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36m_compute_loss\u001b[0;34m(self, batch, model, criterion, config, optimizer_idx)\u001b[0m\n\u001b[1;32m   1142\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1143\u001b[0;31m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_train_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36m_model_train_step\u001b[0;34m(batch, model, criterion, optimizer_idx)\u001b[0m\n\u001b[1;32m   1101\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1102\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/TTS/tts/models/glow_tts.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, batch, criterion)\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# normal training step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             outputs = self.forward(\n\u001b[0m\u001b[1;32m    408\u001b[0m                 \u001b[0mtext_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/TTS/tts/models/glow_tts.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, x_lengths, y, y_lengths, aux_input)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0mlogp4\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mo_mean\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mo_scale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# [b, t, 1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mlogp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogp1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlogp2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlogp3\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlogp4\u001b[0m  \u001b[0;31m# [b, t, t']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m             \u001b[0mattn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmaximum_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 116.00 MiB (GPU 0; 14.75 GiB total capacity; 12.72 GiB already allocated; 44.81 MiB free; 13.27 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-b6cd7ba69c0e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mtraceback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_exc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1838\u001b[0;31m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "trainer.fit()"
      ],
      "id": "d4c07f99-3d1d-4bea-801e-9f33bbff0e9f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cff0c40-2734-40a6-a905-e945a9fb3e98"
      },
      "source": [
        "#### üöÄ Run the Tensorboard. üöÄ\n",
        "On the notebook and Tensorboard, you can monitor the progress of your model. Also Tensorboard provides certain figures and sample outputs."
      ],
      "id": "4cff0c40-2734-40a6-a905-e945a9fb3e98"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5a85cd3b-1646-40ad-a6c2-49323e08eeec"
      },
      "outputs": [],
      "source": [
        "# !pip install tensorboard\n",
        "# !tensorboard --host localhost --logdir=tts_train_dir"
      ],
      "id": "5a85cd3b-1646-40ad-a6c2-49323e08eeec"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9f6dc959"
      },
      "source": [
        "## ‚úÖ Test the model\n",
        "\n",
        "We made it! üôå\n",
        "\n",
        "Let's kick off the testing run, which displays performance metrics.\n",
        "\n",
        "We're committing the cardinal sin of ML üòà (aka - testing on our training data) so you don't want to deploy this model into production. In this notebook we're focusing on the workflow itself, so it's forgivable üòá\n",
        "\n",
        "You can see from the test output that our tiny model has overfit to the data, and basically memorized this one sentence.\n",
        "\n",
        "When you start training your own models, make sure your testing data doesn't include your training data üòÖ"
      ],
      "id": "9f6dc959"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99fada7a-592f-4a09-9369-e6f3d82de3a0"
      },
      "source": [
        "Let's get the latest saved checkpoint."
      ],
      "id": "99fada7a-592f-4a09-9369-e6f3d82de3a0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6dd47ed5-da8e-4bf9-b524-d686630d6961"
      },
      "outputs": [],
      "source": [
        "import glob, os\n",
        "output_path = \"tts_train_dir\"\n",
        "ckpts = sorted([f for f in glob.glob(output_path+\"/*/*.pth\")])\n",
        "configs = sorted([f for f in glob.glob(output_path+\"/*/*.json\")])"
      ],
      "id": "6dd47ed5-da8e-4bf9-b524-d686630d6961"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "dd42bc7a",
        "outputId": "47de8339-bd34-4143-e2d5-8a55d00dbb7a"
      },
      "outputs": [
        {
          "ename": "NotImplementedError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-69-eff64ad56813>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tts --text \"I\\'M a frieezze\"        --model_path /content/tts_train_dir/run-July-20-2023_09+40AM-0000000/best_model_406.pth        --config_path /content/tts_train_dir/run-July-20-2023_09+40AM-0000000/config.json        --out_path out.wav'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 99\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    451\u001b[0m   \u001b[0;31m# is expected to call this function, thus adding one level of nesting to the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m   result = _run_command(\n\u001b[0m\u001b[1;32m    454\u001b[0m       \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclear_streamed_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m   )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    165\u001b[0m   \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlocale\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetpreferredencoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mlocale_encoding\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0m_ENCODING\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     raise NotImplementedError(\n\u001b[0m\u001b[1;32m    168\u001b[0m         \u001b[0;34m'A UTF-8 locale is required. Got {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocale_encoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     )\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: A UTF-8 locale is required. Got ANSI_X3.4-1968"
          ]
        }
      ],
      "source": [
        "!tts --text \"I'M a frieezze\" \\\n",
        "      --model_path /content/tts_train_dir/run-July-20-2023_09+40AM-0000000/best_model_406.pth \\\n",
        "      --config_path /content/tts_train_dir/run-July-20-2023_09+40AM-0000000/config.json \\\n",
        "      --out_path out.wav"
      ],
      "id": "dd42bc7a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81cbcb3f-d952-469b-a0d8-8941cd7af670"
      },
      "source": [
        "## üì£ Listen to the synthesized wave üì£"
      ],
      "id": "81cbcb3f-d952-469b-a0d8-8941cd7af670"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "id": "e0000bd6-6763-4a10-a74d-911dd08ebcff",
        "outputId": "1f16db7a-5068-4da7-a15a-82e95be13d0e"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "                <audio  controls=\"controls\" >\n",
              "                    <source src=\"data:audio/x-wav;base64,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\" type=\"audio/x-wav\" />\n",
              "                    Your browser does not support the audio element.\n",
              "                </audio>\n",
              "              "
            ],
            "text/plain": [
              "<IPython.lib.display.Audio object>"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import IPython\n",
        "IPython.display.Audio(\"out.wav\")"
      ],
      "id": "e0000bd6-6763-4a10-a74d-911dd08ebcff"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13914401-cad1-494a-b701-474e52829138"
      },
      "source": [
        "## üéâ Congratulations! üéâ You now have trained your first TTS model!\n",
        "Follow up with the next tutorials to learn more advanced material."
      ],
      "id": "13914401-cad1-494a-b701-474e52829138"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download('/content/tts_train_dir/run-July-20-2023_12+01PM-0000000/config.json')\n",
        "files.download('/content/dataset/metadata.csv')"
      ],
      "id": "950d9fc6-896f-4a2c-86fd-8fd1fcbbb3f7"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}